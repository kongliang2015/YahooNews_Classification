{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- encoding: utf-8 -*-\n",
    "from __future__ import print_function  \n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer  \n",
    "from keras.preprocessing.sequence import pad_sequences  \n",
    "from keras.utils.np_utils import to_categorical  \n",
    "from keras.layers import Dense, Input, Flatten,Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding  \n",
    "from keras.models import Model  \n",
    "from keras.optimizers import *  \n",
    "from keras.models import Sequential  \n",
    "from keras.layers import Merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainModel(data,target,modelFile):\n",
    "    # 划分数据集\n",
    "    train_set,test_set,train_tag,test_tag = train_test_split(data,target, test_size = 0.3)\n",
    "    \n",
    "    # 把一维的标签做onehot，pd.get_dummies的结果是df,把df转为ndarray (as_matrix())\n",
    "    train_label = pd.get_dummies(train_tag).as_matrix()\n",
    "    test_label = pd.get_dummies(test_tag).as_matrix()\n",
    "    \n",
    "    print('shape of train set:',train_set.shape)\n",
    "    print('shape of train label:',train_label.shape)\n",
    "    print('shape of test set:',test_set.shape)\n",
    "    print('shape of test label:',test_label.shape)\n",
    "    \n",
    "    # 读入模型   \n",
    "    model = models.Word2Vec.load(modelFile)\n",
    "    # 读入word2vec模型提供的嵌入层，权重需要训练\n",
    "    model_embedding = model.wv.get_embedding_layer(train_embeddings=False)\n",
    "\n",
    "    # 训练嵌入层权重\n",
    "    kmodel = Sequential()\n",
    "    kmodel.add(model_embedding)\n",
    "    kmodel.compile('rmsprop', 'mse')\n",
    "    \n",
    "#     print(model_embedding.get_weights())\n",
    "        \n",
    "    # 第一个卷积（卷积窗口是5*200）\n",
    "    model = Sequential() \n",
    "\n",
    "    # 定义嵌入层\n",
    "    # trainable=True 通过训练来更新权重\n",
    "    # trainable=Fasle 由于使用了word2vec提供的权重，这里不用再训练了\n",
    "    embedding_layer = Embedding(input_dim = model_embedding.input_dim,\n",
    "                                output_dim = 50,\n",
    "                                input_length = 200,\n",
    "                                weights = model_embedding.get_weights(),\n",
    "                                trainable = False)\n",
    "    # 使用word2vec训练好的嵌入层\n",
    "    model.add(embedding_layer)\n",
    "    \n",
    "    model.add(Conv1D(50, 3, padding='same',activation='relu')) \n",
    "    model.add(MaxPooling1D(2)) \n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv1D(100, 3, padding='same',activation='relu')) \n",
    "    model.add(MaxPooling1D(2)) \n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())  \n",
    "    \n",
    "    model.add(Dense(50, activation='relu')) # 全连接层  \n",
    "    model.add(Dense(20, activation='relu')) # 全连接层  \n",
    "    model.add(Dense(10, activation='softmax')) # softmax，输出文本属于20种类别中每个类别的概率  \n",
    "        \n",
    "    # 优化器我这里用了adadelta，也可以使用其他方法  \n",
    "    model.compile(loss='categorical_crossentropy',  \n",
    "                  optimizer='Adadelta',  \n",
    "                  metrics=['accuracy'])  \n",
    "\n",
    "    # =下面开始训练，nb_epoch是迭代次数，可以高一些，训练效果会更好，但是训练会变慢  \n",
    "    model.fit(train_set, train_label,nb_epoch=10,batch_size = 100)  \n",
    "\n",
    "    score = model.evaluate(train_set, train_label, verbose=0) # 评估模型在训练集中的效果，准确率约99%  \n",
    "    print('train score:', score[0])  \n",
    "    print('train accuracy:', score[1])  \n",
    "    \n",
    "    score = model.evaluate(test_set,test_label, verbose=0)  # 评估模型在测试集中的效果，准确率约为97%，迭代次数多了，会进一步提升  \n",
    "    print('Test score:', score[0])  \n",
    "    print('Test accuracy:', score[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    inFile = \"./data/train_cnn.npy\"\n",
    "    modelFile = \"./model/w2v_dim50.mdl\"\n",
    "    targetData = \"./data/target.npy\"\n",
    "    vecFile = \"./model/vector.bin\"\n",
    "    \n",
    "    data_all = np.load(inFile)\n",
    "    target = np.load(targetData)\n",
    "    \n",
    "#     print(data_all[:10,])\n",
    "#     print(target[:10])\n",
    "    # 训练模 \n",
    "    trainModel(data_all,target,modelFile)  \n",
    "    \n",
    "    # 测试模型\n",
    "#     useModel(modelFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
