{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "8129c87d-1fcf-45b0-997a-ebaa58d9e6bd"
    }
   },
   "outputs": [],
   "source": [
    "# -*- encoding: utf-8 -*-\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "824c0bd6-6bdf-426b-a3fc-aed982b75127"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "import collections  #用来统计词频\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "54fc59dc-062d-4b17-999e-c4523c7bffe6"
    }
   },
   "outputs": [],
   "source": [
    "def getLable(x):\n",
    "    if x == 'NEGATIVE':\n",
    "        lable = 0\n",
    "    elif x== 'POSITIVE':\n",
    "        lable = 1\n",
    "    else:\n",
    "        lable = -1\n",
    "        print x\n",
    "    return lable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "c10e88ce-d91c-4eda-a086-7d33ccec1ff1"
    }
   },
   "outputs": [],
   "source": [
    "# 获取训练数据\n",
    "def getTrainSet(inFile):\n",
    "    # 训练集\n",
    "    train_set=[]\n",
    "    # 情感标签集\n",
    "    target_set = []\n",
    "    # 统计所有出现的词\n",
    "    word_ctr = collections.Counter()\n",
    "    # 评论的最大长度\n",
    "    maxlen = 0\n",
    "    len_ctr = collections.Counter()\n",
    "    \n",
    "    # 读入训练数据           \n",
    "    f=open(inFile)\n",
    "    lines=f.readlines()\n",
    "    for line in lines:\n",
    "        article = line.replace('\\n','').split('\\t')\n",
    "\n",
    "        # 情感标签\n",
    "        target_set.append(getLable(article[0]))\n",
    "\n",
    "        # 内容\n",
    "        content = article[1:]\n",
    "        train_set.append(content)\n",
    "\n",
    "        # 获得评论的最大长度\n",
    "        if len(content) > maxlen:\n",
    "            maxlen = len(content)\n",
    "\n",
    "        # 统计各种长度的文章个数\n",
    "        len_ctr[str(len(content))] += 1\n",
    "\n",
    "        # 统计所有出现的词\n",
    "        for w in content:\n",
    "            word_ctr[w] += 1\n",
    "\n",
    "    f.close()\n",
    "        \n",
    "    print('max_len ',maxlen)\n",
    "    print('nb_words ', len(word_ctr))\n",
    "#     print ('len_ctr ', len_ctr)\n",
    "    return (target_set,train_set,word_ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # 获取测试数据\n",
    "def getTestSet(inFile):\n",
    "    # 训练集\n",
    "    train_set=[]\n",
    "    # 情感标签集\n",
    "    docid_set = []\n",
    "    # 统计所有出现的词\n",
    "    word_ctr = collections.Counter()\n",
    "    \n",
    "    # 读入训练数据\n",
    "    f=open(inFile)\n",
    "    lines=f.readlines()\n",
    "    for line in lines:\n",
    "        article = line.replace('\\n','').split('\\t')\n",
    "        \n",
    "        # 情感标签\n",
    "        docid_set.append(article[0])\n",
    "       \n",
    "        # 内容\n",
    "        content = article[1:]\n",
    "        train_set.append(content)\n",
    "        \n",
    "        # 统计所有出现的词\n",
    "        for w in content:\n",
    "            word_ctr[w] += 1\n",
    "\n",
    "    f.close()\n",
    "    print('nb_words ', len(word_ctr))\n",
    "    return (docid_set,train_set,word_ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 把原始文本转化为由词汇表索引表示的矩阵\n",
    "def dataTransform(inFile,outFile,maxfeat,seqlen):\n",
    "    # 读入训练数据\n",
    "    print \"read file:\",inFile[0]\n",
    "    target_set,train_set,word_ctr = getTrainSet(inFile[0])\n",
    "    \n",
    "    # 读入测试数据\n",
    "    print \"read file:\",inFile[1]\n",
    "    docid_set,test_set,word_ctr_test = getTestSet(inFile[1])    \n",
    "    \n",
    "    # 实际标题的长度很多在20左右\n",
    "    MAX_SENTENCE_LENGTH = seqlen\n",
    "    \n",
    "    # ('nb_words ', 236825)\n",
    "    MAX_FEATURES = maxfeat\n",
    "        \n",
    "    # 合并词表 适用update()方法\n",
    "    word_ctr.update(word_ctr_test)\n",
    "    print \"new word_ctr:\",len(word_ctr)\n",
    "    \n",
    "    # 对于不在词汇表里的单词，把它们用伪单词 UNK 代替。 \n",
    "    # 根据句子的最大长度 (max_lens)，我们可以统一句子的长度，把短句用 0 填充。\n",
    "    # 接下来建立两个 lookup tables，分别是 word2index 和 index2word，用于单词和数字转换。 \n",
    "    vocab_size = min(MAX_FEATURES, len(word_ctr)) + 2\n",
    "    word2index = {x[0]: i+2 for i, x in enumerate(word_ctr.most_common(MAX_FEATURES))}\n",
    "    word2index[\"PAD\"] = 0\n",
    "    word2index[\"UNK\"] = 1\n",
    "    index2word = {v:k for k, v in word2index.items()}\n",
    "    \n",
    "#     np.save(\"./model/word2index.npy\",word2index)\n",
    "#     np.save(\"./model/index2word.npy\",index2word)\n",
    "    \n",
    "    # 对训练数据做转换  \n",
    "    X = np.empty(len(train_set),dtype=list)\n",
    "    y = np.array([int(i) for i in target_set])\n",
    "    \n",
    "    i = 0\n",
    "    for news in train_set:\n",
    "        trs_news = []\n",
    "        for w in news:\n",
    "            if w in word2index:\n",
    "                trs_news.append(word2index[w])\n",
    "            else:\n",
    "                trs_news.append(word2index['UNK'])\n",
    "        X[i] = trs_news\n",
    "        i += 1\n",
    "    print \"%s train files is transformed.\" % (i)\n",
    "        \n",
    "    \n",
    "    # 对文字序列做补齐 ，补齐长度=最长的文章长度 ，补齐在最后，补齐用的词汇默认是词汇表index=0的词汇，也可通过value指定\n",
    "    # 训练好的w2v词表的index = 0 对应的词汇是空格\n",
    "    X = sequence.pad_sequences(X,maxlen=MAX_SENTENCE_LENGTH,padding='post')\n",
    "    \n",
    "    print \"save train set matirx to np file...\"\n",
    "    \n",
    "    np.save(outFile[0],np.column_stack([X,y]))\n",
    "    \n",
    "    ####################\n",
    "    # 对测试数据做转换    \n",
    "    # 生成一个<idx,doc_id>键值对\n",
    "    tmp = [[idx,docid] for idx,docid in enumerate(docid_set)]\n",
    "    # 序列化\n",
    "    with open(outFile[2], 'wb') as f:\n",
    "        pickle.dump(tmp, f)\n",
    "    \n",
    "    Xt = np.empty(len(test_set),dtype=list)\n",
    "    yt = np.array([int(i[0]) for i in tmp])\n",
    "    \n",
    "    i = 0\n",
    "    for news in test_set:\n",
    "        trs_news = []\n",
    "        for w in news:\n",
    "            if w in word2index:\n",
    "                trs_news.append(word2index[w])\n",
    "            else:\n",
    "                trs_news.append(word2index['UNK'])\n",
    "        Xt[i] = trs_news\n",
    "        i += 1\n",
    "    print \"%s test files is transformed.\" % (i)\n",
    "        \n",
    "    \n",
    "    # 对文字序列做补齐 ，补齐长度=最长的文章长度 ，补齐在最后，补齐用的词汇默认是词汇表index=0的词汇，也可通过value指定\n",
    "    # 训练好的w2v词表的index = 0 对应的词汇是空格\n",
    "    Xt = sequence.pad_sequences(Xt,maxlen=MAX_SENTENCE_LENGTH,padding='post')\n",
    "    \n",
    "    print \"save test set matirx to np file...\"\n",
    "    \n",
    "    np.save(outFile[1],np.column_stack([Xt,yt]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run(trainFile,matFile):\n",
    "    \n",
    "    # 定义词典长度\n",
    "    FEATURES = 2000000\n",
    "    # 定义序列长度\n",
    "#     SENTENCE_LENGTH = 20\n",
    "    SENTENCE_LENGTH = 200\n",
    "    \n",
    "    # 把训练文本转化为矩阵\n",
    "    dataTransform(trainFile,matFile,FEATURES,SENTENCE_LENGTH)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "7bdd1240-611b-49a0-a6ad-965ff9963eb7"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # 定义文件路径\n",
    "    dataPath = \"/home/hadoop/DataSencise/bdci2017/BDCI2017-360/data/\"\n",
    "    mdlPath = \"/home/hadoop/DataSencise/bdci2017/BDCI2017-360/model/\"\n",
    "    \n",
    "    # 定义训练文件名\n",
    "    trainFile_title = dataPath + \"train/train_output_title.tsv\"\n",
    "    # 定义输出文件名\n",
    "    train_matFile_title = mdlPath + \"train_matrix_title.npy\"    \n",
    "    \n",
    "    trainFile_content = dataPath + \"train/train_output_content.tsv\"\n",
    "    train_matFile_content = mdlPath + \"train_matrix_content.npy\"\n",
    "        \n",
    "    # 定义测试文件名\n",
    "    testFile_title = dataPath + \"test/test_output_title.tsv\"\n",
    "    # 定义输出文件名\n",
    "    test_matFile_title = mdlPath + \"test_matrix_title.npy\"\n",
    "    \n",
    "    testFile_content = dataPath + \"test/test_output_content.tsv\"    \n",
    "    test_matFile_content = mdlPath + \"test_matrix_content.npy\"\n",
    "    \n",
    "    # <idx,doc_id>键值对文件\n",
    "    train_pkl = mdlPath + \"train_pkl.txt\"\n",
    "        \n",
    "    # 把所有文件的标题读入，建立字典，把原标题转化为矩阵\n",
    "    run([trainFile_title,testFile_title],[train_matFile_title,test_matFile_title,train_pkl])\n",
    "    \n",
    "    # 转换内容文件\n",
    "#     run([trainFile_content,testFile_content],[train_matFile_content,test_matFile_content,train_pkl])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "8b8cf1de-9022-49be-b313-53576d25f2d6"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nbpresent": {
   "slides": {
    "00e2a19c-743b-44fb-bcdd-72f433ff69a6": {
     "id": "00e2a19c-743b-44fb-bcdd-72f433ff69a6",
     "prev": "b5ccee10-2a12-4efe-ab54-a54af9e550e6",
     "regions": {
      "01d0b004-81de-4594-b3d0-4210929f50d5": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "824c0bd6-6bdf-426b-a3fc-aed982b75127",
        "part": "whole"
       },
       "id": "01d0b004-81de-4594-b3d0-4210929f50d5"
      }
     }
    },
    "2b891ec3-7b9c-4283-94e4-7a56b5140890": {
     "id": "2b891ec3-7b9c-4283-94e4-7a56b5140890",
     "prev": "c9ac04e8-52ce-42a2-8e48-387af5ea269b",
     "regions": {
      "647ed211-96cf-415f-8d4d-be514f012c24": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "c10e88ce-d91c-4eda-a086-7d33ccec1ff1",
        "part": "whole"
       },
       "id": "647ed211-96cf-415f-8d4d-be514f012c24"
      }
     }
    },
    "3b0142e5-542a-4e40-8092-bf8686d1dc2e": {
     "id": "3b0142e5-542a-4e40-8092-bf8686d1dc2e",
     "prev": "2b891ec3-7b9c-4283-94e4-7a56b5140890",
     "regions": {
      "10efe84d-25e7-4dc2-b53a-9c2b8d5d706b": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "2d486198-13b6-4a79-a0fb-75473daf81d0",
        "part": "whole"
       },
       "id": "10efe84d-25e7-4dc2-b53a-9c2b8d5d706b"
      }
     }
    },
    "982d1bde-a086-4057-8c58-18dd7e332616": {
     "id": "982d1bde-a086-4057-8c58-18dd7e332616",
     "prev": "d0210d36-bf14-4d0b-bd83-d813a6011c7f",
     "regions": {
      "3d83836a-f6c0-4bcc-9fee-a6938d756d46": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "8b8cf1de-9022-49be-b313-53576d25f2d6",
        "part": "whole"
       },
       "id": "3d83836a-f6c0-4bcc-9fee-a6938d756d46"
      }
     }
    },
    "b5ccee10-2a12-4efe-ab54-a54af9e550e6": {
     "id": "b5ccee10-2a12-4efe-ab54-a54af9e550e6",
     "prev": null,
     "regions": {
      "900e725f-ccd4-4607-a252-c34610d47568": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "8129c87d-1fcf-45b0-997a-ebaa58d9e6bd",
        "part": "whole"
       },
       "id": "900e725f-ccd4-4607-a252-c34610d47568"
      }
     }
    },
    "bde1bbb0-7120-4b43-b688-9df2cdf7a56c": {
     "id": "bde1bbb0-7120-4b43-b688-9df2cdf7a56c",
     "prev": "3b0142e5-542a-4e40-8092-bf8686d1dc2e",
     "regions": {
      "2bee5c52-2bbe-472a-a811-56e22ddc23b9": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4e689995-d4b9-4c9b-9eac-5b3028ef5fc3",
        "part": "whole"
       },
       "id": "2bee5c52-2bbe-472a-a811-56e22ddc23b9"
      }
     }
    },
    "c9ac04e8-52ce-42a2-8e48-387af5ea269b": {
     "id": "c9ac04e8-52ce-42a2-8e48-387af5ea269b",
     "prev": "00e2a19c-743b-44fb-bcdd-72f433ff69a6",
     "regions": {
      "5941affb-98ed-4e93-bfca-e73c43afb74d": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "c61e044a-4227-47de-838a-843e116cc077",
        "part": "whole"
       },
       "id": "5941affb-98ed-4e93-bfca-e73c43afb74d"
      }
     }
    },
    "cb677454-b7ae-4eae-b0dd-1e8bc248fd47": {
     "id": "cb677454-b7ae-4eae-b0dd-1e8bc248fd47",
     "prev": "bde1bbb0-7120-4b43-b688-9df2cdf7a56c",
     "regions": {
      "1dd8cdac-9314-432d-87b7-8ba93b0b94c0": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "54fc59dc-062d-4b17-999e-c4523c7bffe6",
        "part": "whole"
       },
       "id": "1dd8cdac-9314-432d-87b7-8ba93b0b94c0"
      }
     }
    },
    "d0210d36-bf14-4d0b-bd83-d813a6011c7f": {
     "id": "d0210d36-bf14-4d0b-bd83-d813a6011c7f",
     "prev": "cb677454-b7ae-4eae-b0dd-1e8bc248fd47",
     "regions": {
      "c4048389-1fe4-4503-91b2-411c223d3f82": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "7bdd1240-611b-49a0-a6ad-965ff9963eb7",
        "part": "whole"
       },
       "id": "c4048389-1fe4-4503-91b2-411c223d3f82"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
