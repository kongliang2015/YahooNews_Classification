{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- encoding: utf-8 -*-\n",
    "import sys\n",
    "import logging\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reload(sys)\n",
    "# sys.setdefaultencoding('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainSkipgram(inFile,mdlfile):\n",
    "    # Skipgram model\n",
    "    model = fasttext.skipgram(input_file=inFile,\\\n",
    "                              output=mdlfile,\\\n",
    "                              lr=0.1,\\\n",
    "                              dim=200,\\\n",
    "                              epoch=10,\\\n",
    "                              word_ngrams=3,\\\n",
    "                              bucket=5000000)\n",
    "#     print \"Skipgram model words:\",model.words # list of words in dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainCBOW(inFile,mdlfile):\n",
    "    # CBOW model\n",
    "    model = fasttext.cbow(input_file=inFile,\\\n",
    "                              output=mdlfile,\\\n",
    "                              lr=0.1,\\\n",
    "                              dim=200,\\\n",
    "                              epoch=10,\\\n",
    "                              word_ngrams=3,\\\n",
    "                              bucket=5000000)\n",
    "#     print \"CBOW model words:\",model.words # list of words in dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainCLF(inFile,model,vec):\n",
    "    #训练模型\n",
    "    classifier = fasttext.supervised(input_file=inFile,\\\n",
    "                                     output=model,\\\n",
    "                                     label_prefix=\"__label__\",\\\n",
    "                                     dim = 200,\\\n",
    "                                     word_ngrams = 2,\\\n",
    "                                     epoch = 10,\\\n",
    "                                     pretrained_vectors = vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(inFile,model):\n",
    "    #load训练好的模型\n",
    "    classifier = fasttext.load_model(model)\n",
    "    \n",
    "    result = classifier.test(inFile)\n",
    "    print 'P@1:', result.precision\n",
    "    print 'R@1:', result.recall\n",
    "    print 'Number of examples:', result.nexamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # 获取测试数据\n",
    "def getTestSet(inFile):\n",
    "    # 训练集\n",
    "    train_set=[]\n",
    "    # 情感标签集\n",
    "    docid_set = []\n",
    "   \n",
    "    # 读入训练数据\n",
    "    f=open(inFile)\n",
    "    lines=f.readlines()\n",
    "    for line in lines:\n",
    "        article = line.replace('\\n','').split(\" \")\n",
    "        \n",
    "        # 文章id\n",
    "        docid_set.append(article[0])\n",
    "       \n",
    "        # 内容\n",
    "        content = article[1:]\n",
    "        train_set.append(content)        \n",
    "\n",
    "    f.close()\n",
    "    return (train_set,docid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 把分词以后的结果写入文件\n",
    "def writeFile(outputfile,newline):\n",
    "    \n",
    "    fw = open(outputfile, 'ab')\n",
    "    fw.write(newline.encode(\"utf-8\"))\n",
    "    fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred(inFile,model,outputfile):\n",
    "    \n",
    "    # 读入测试文件\n",
    "    testData,docid = getTestSet(inFile)\n",
    "    for t in testData:\n",
    "        for i in t:\n",
    "            print i\n",
    "   \n",
    "    #load训练好的模型\n",
    "    classifier = fasttext.load_model(model,label_prefix='__label__')\n",
    "    for idx,text in enumerate(testData):\n",
    "#         print text\n",
    "        label = classifier.predict(text)\n",
    "#         print len(label)\n",
    "        newline = docid[idx] + \" \" + label +  \"\\n\"\n",
    "        \n",
    "        writeFile(outputfile,newline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadMdl(mdl):\n",
    "    model = fasttext.load_model(mdl, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "   \n",
    "    # 定义文件路径\n",
    "    dataPath = \"/home/hadoop/DataSencise/bdci2017/BDCI2017-360/data/\"\n",
    "    mdlPath = \"/home/hadoop/DataSencise/bdci2017/BDCI2017-360/model/\"\n",
    "    \n",
    "    # 定义训练文件名\n",
    "#     inFile = dataPath + \"train/train_output_title.tsv\"\n",
    "    inFile = dataPath + \"train/train_all.tsv\"\n",
    "    \n",
    "    # test 文件\n",
    "    testFile = dataPath + \"test/test_all.tsv\"\n",
    "    \n",
    "    # test 文件\n",
    "    outFile = dataPath + \"test/pred_output.tsv\"\n",
    "    \n",
    "    # 定义vec模型\n",
    "    model_skipgram = mdlPath + \"vec_skipgram\"\n",
    "    # 定义vec模型\n",
    "    model_CBOW = mdlPath + \"vec_CBOW\"\n",
    "    \n",
    "    # 定义clf模型\n",
    "    model_clf_sg = mdlPath + \"clf_model_sg\"\n",
    "    \n",
    "    # 定义clf模型\n",
    "    model_clf_CBOW = mdlPath + \"clf_model_CBOW\"\n",
    "\n",
    "    # 训练vector\n",
    "    trainSkipgram(inFile,model_skipgram)\n",
    "\n",
    "    # 训练vector\n",
    "#     trainCBOW(inFile,model_CBOW)\n",
    "    \n",
    "    vec_skipgram = model_skipgram + \".vec\"\n",
    "    vec_CBOW = model_CBOW + \".vec\"\n",
    "    \n",
    "    # 分类 使用skipgram\n",
    "#     trainCLF(inFile,model_clf_sg,vec_skipgram)\n",
    "    \n",
    "#     trainCLF(inFile,model_clf_CBOW,vec_CBOW)\n",
    "    \n",
    "    # 定义clf模型\n",
    "    bin_clf_sg = model_clf_sg + \".bin\"\n",
    "    \n",
    "    # 定义clf模型\n",
    "    bin_clf_CBOW = model_clf_CBOW + \".bin\"\n",
    "    \n",
    "    # 测试\n",
    "#     pred(testFile,bin_clf_sg,outFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
